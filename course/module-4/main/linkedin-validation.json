[
  {
    "instruction": "Introduce a Python package that significantly speeds up text preprocessing pipelines for ML applications.",
    "post": "Using this ğ—£ğ˜†ğ˜ğ—µğ—¼ğ—» ğ—½ğ—®ğ—°ğ—¸ğ—®ğ—´ğ—², you can ğ˜…ğŸ­ğŸ¬ your ğ˜ğ—²ğ˜…ğ˜ ğ—½ğ—¿ğ—²ğ—½ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—²ğ˜€. \n\nAny text preprocessing pipeline has to clean, partition, extract, or chunk text data to feed it into your LLMs. \n\nğ˜‚ğ—»ğ˜€ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²ğ—± offers a ğ—¿ğ—¶ğ—°ğ—µ and ğ—°ğ—¹ğ—²ğ—®ğ—» ğ—”ğ—£ğ—œ that allows you to quickly: \n\n- ğ˜±ğ˜¢ğ˜³ğ˜µğ˜ªğ˜µğ˜ªğ˜°ğ˜¯ your data into smaller segments from various data sources (e.g., HTML, CSV, PDFs, even images, etc.) \n- ğ˜¤ğ˜­ğ˜¦ğ˜¢ğ˜¯ğ˜ªğ˜¯ğ˜¨ the text of anomalies (e.g., wrong ASCII characters), any irrelevant information (e.g., white spaces, bullets, etc.), and filling missing values \n- ğ˜¦ğ˜¹ğ˜µğ˜³ğ˜¢ğ˜¤ğ˜µğ˜ªğ˜¯ğ˜¨ information from pieces of text (e.g., datetimes, addresses, IP addresses, etc.) \n- ğ˜¤ğ˜©ğ˜¶ğ˜¯ğ˜¬ğ˜ªğ˜¯ğ˜¨ your text segments into pieces of text that can be inserted into your embedding model \n- ğ˜¦ğ˜®ğ˜£ğ˜¦ğ˜¥ğ˜¥ğ˜ªğ˜¯ğ˜¨ data (e.g., wrapper over OpenAIEmbeddingEncoder, HuggingFaceEmbeddingEncoders, etc.) \n- ğ˜´ğ˜µğ˜¢ğ˜¨ğ˜¦ your data to be fed into various tools (e.g., Label Studio, Label Box, etc.) \n\nğ—”ğ—¹ğ—¹ ğ˜ğ—µğ—²ğ˜€ğ—² ğ˜€ğ˜ğ—²ğ—½ğ˜€ ğ—®ğ—¿ğ—² ğ—²ğ˜€ğ˜€ğ—²ğ—»ğ˜ğ—¶ğ—®ğ—¹ ğ—³ğ—¼ğ—¿: \n\n- feeding your data into your LLMs \n- embedding the data and ingesting it into a vector DB \n- doing RAG \n- labeling \n- recommender systems \n\n... basically for any LLM or multimodal applications \n\n. \n\nImplementing all these steps from scratch will take a lot of time. \n\nI know some Python packages already do this, but the functionality is scattered across multiple packages. \n\nğ˜‚ğ—»ğ˜€ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²ğ—± packages everything together under a nice, clean API. \n\nâ†³ Check it out: ğŸ”— \nhttps://lnkd.in/dCACT3K2 \n\nhashtag\n#machinelearning \nhashtag\n#mlops \nhashtag\n#datascience \n\n. \n\nğŸ’¡ Follow me for daily lessons about ML engineering and MLOps."
  },
  {
    "instruction": "Share a personal achievement related to your growth on LinkedIn and reflect on your journey.",
    "post": "Hello there ğŸ‘‹ I recently passed ğŸ®ğŸ±ğ—¸+ ğ—³ğ—¼ğ—¹ğ—¹ğ—¼ğ˜„ğ—²ğ—¿ğ˜€ on LinkedIn. \n\nThis is not a bragging post. \n\nI want to say a big \"ğ˜›ğ˜©ğ˜¢ğ˜¯ğ˜¬ ğ˜ºğ˜°ğ˜¶!\" to everyone who followed me and found my content helpful. \n\nI am incredibly grateful for that. \n\nI started posting more consistently ~1 year ago when I knew nothing about writing content or social media in general. \n\nThe heck, I wasn't spending time on social media... \n\nI will be honest with you. I am still shocked that some of my posts reached >100k views. \n\n. \n\nAnyhow, I will continue improving my craft, pretending I know what I do, and providing high-quality content on: \n\n- ML engineering \n- MLOps \n- LLMs \n- Python & Software Engineering applied in the world of ML \n\nI am here for the long run. \n\n. \n\nğ˜‰ğ˜¢ğ˜´ğ˜¦ğ˜¥ ğ˜°ğ˜¯ ğ˜ºğ˜°ğ˜¶ğ˜³ ğ˜¦ğ˜¯ğ˜¨ğ˜¢ğ˜¨ğ˜¦ğ˜®ğ˜¦ğ˜¯ğ˜µ, ğ˜©ğ˜¦ğ˜³ğ˜¦ ğ˜¢ğ˜³ğ˜¦ ğ˜´ğ˜°ğ˜®ğ˜¦ ğ˜°ğ˜§ ğ˜®ğ˜º ğ˜£ğ˜¦ğ˜´ğ˜µ ğ˜±ğ˜°ğ˜´ğ˜µğ˜´ ğ˜§ğ˜³ğ˜°ğ˜® ğ˜µğ˜©ğ˜¦ ğ˜­ğ˜¢ğ˜µğ˜¦ğ˜´ğ˜µ ğ˜ºğ˜¦ğ˜¢ğ˜³: \n\n- The internet is full of ğ—¹ğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—¿ğ—²ğ˜€ğ—¼ğ˜‚ğ—¿ğ—°ğ—²ğ˜€ about ğ—Ÿğ—Ÿğ— ğ˜€ & ğ˜ƒğ—²ğ—°ğ˜ğ—¼ğ—¿ ğ——ğ—•ğ˜€. But ğ—ºğ—¼ğ˜€ğ˜ ğ—¼ğ—³ ğ—¶ğ˜ is ğ˜ğ—¿ğ—®ğ˜€ğ—µ: ğŸ”— https://lnkd.in/dPvmUH6G \n\n- To successfully use ğ—¥ğ—”ğ—š in your ğ—Ÿğ—Ÿğ—  ğ—®ğ—½ğ—½ğ—¹ğ—¶ğ—°ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€, your ğ˜ƒğ—²ğ—°ğ˜ğ—¼ğ—¿ ğ——ğ—• must constantly be updated with the latest data: ğŸ”— https://lnkd.in/d7gH_SeX \n\n- Writing your own ML models is history: ğŸ”— https://lnkd.in/ddhxpDAe \n\n- Want to ğ—¹ğ—²ğ—®ğ—¿ğ—» ğ— ğ—Ÿ & ğ— ğ—Ÿğ—¢ğ—½ğ˜€ ğ—¶ğ—» ğ—® ğ˜€ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²ğ—± ğ˜„ğ—®ğ˜†?: ğŸ”— https://lnkd.in/dqv4d3-w \n\n- The whole field of prompt engineering can be reduced to these 6 techniques I use almost daily when using ChatGPT (or other LLMs): ğŸ”— https://lnkd.in/drr9C5cy \n\n- Want to build your first ğ—Ÿğ—Ÿğ—  ğ—½ğ—¿ğ—¼ğ—·ğ—²ğ—°ğ˜ but don't know where to start?: ğŸ”— https://lnkd.in/dhfKcYkh \n\n. \n\nAgain, \"Thank you\" for following me and let's master ML engineering together ğŸ”¥"
  },
  {
    "instruction": "Discuss strategies for adding real-time monitoring to ML systems on LinkedIn, focusing on different scenarios based on the availability of ground truth data. Highlight the importance of continuous model performance evaluation for maintaining system integrity.",
    "post": "ğ—›ğ—¼ğ˜„ ğ˜ğ—¼ ğ—®ğ—±ğ—± ğ—¿ğ—²ğ—®ğ—¹-ğ˜ğ—¶ğ—ºğ—² ğ—ºğ—¼ğ—»ğ—¶ğ˜ğ—¼ğ—¿ğ—¶ğ—»ğ—´ ğ—®ğ—»ğ—± ğ—ºğ—²ğ˜ğ—¿ğ—¶ğ—°ğ˜€ to your ML system.\nYour model is exposed to performance degradation after it is deployed to production.\nThat is why you need to monitor it constantly.\nThe most common way to monitor an ML model is to compute its metrics.\nBut for that, you need the ground truth.\nğ—œğ—» ğ—½ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ğ—¶ğ—¼ğ—», ğ˜†ğ—¼ğ˜‚ ğ—°ğ—®ğ—» ğ—®ğ˜‚ğ˜ğ—¼ğ—ºğ—®ğ˜ğ—¶ğ—°ğ—®ğ—¹ğ—¹ğ˜† ğ—®ğ—°ğ—°ğ—²ğ˜€ğ˜€ ğ˜ğ—µğ—² ğ—´ğ—¿ğ—¼ğ˜‚ğ—»ğ—± ğ˜ğ—¿ğ˜‚ğ˜ğ—µ ğ—¶ğ—» ğŸ¯ ğ—ºğ—®ğ—¶ğ—» ğ˜€ğ—°ğ—²ğ—»ğ—®ğ—¿ğ—¶ğ—¼ğ˜€:\n1. near real-time: you can access it quite quickly\n2. delayed: you can access it after a considerable amount of time (e.g., one month)\n3. never: you have to label the data manually\n.\nğ—™ğ—¼ğ—¿ ğ˜‚ğ˜€ğ—² ğ—°ğ—®ğ˜€ğ—²ğ˜€ ğŸ®. ğ—®ğ—»ğ—± ğŸ¯. ğ˜†ğ—¼ğ˜‚ ğ—°ğ—®ğ—» ğ—¾ğ˜‚ğ—¶ğ—°ğ—¸ğ—¹ğ˜† ğ—°ğ—¼ğ—ºğ—½ğ˜‚ğ˜ğ—² ğ˜†ğ—¼ğ˜‚ğ—¿ ğ—ºğ—¼ğ—»ğ—¶ğ˜ğ—¼ğ—¿ğ—¶ğ—»ğ—´ ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—² ğ—¶ğ—» ğ˜ğ—µğ—² ğ—³ğ—¼ğ—¹ğ—¹ğ—¼ğ˜„ğ—¶ğ—»ğ—´ ğ˜„ğ—®ğ˜†:\n- store the model predictions and GT as soon as they are available (these 2 will be out of sync -> you can't compute the metrics right away)\n- build a DAG (e.g., using Airflow) that extracts the predictions & GT computes the metrics in batch mode and loads them into another storage (e.g., GCS)\n- use an orchestration tool to run the DAG in the following scenarios:\n1. scheduled: if the GT is available in near real-time (e.g., hourly), then it makes sense to run your monitoring pipeline based on the known frequency\n2. triggered: if the GT is delayed and you don't know when it may come up, then you can implement a webhook to trigger your monitoring pipeline\n- attach a consumer to your storage to use and display the metrics (e.g., trigger alarms and display them in a dashboard)\n.\nIf you want to see how to implement a near real-time monitoring pipeline using Airflow and GCS, check out my article: ğ˜Œğ˜¯ğ˜´ğ˜¶ğ˜³ğ˜ªğ˜¯ğ˜¨ ğ˜›ğ˜³ğ˜¶ğ˜´ğ˜µğ˜¸ğ˜°ğ˜³ğ˜µğ˜©ğ˜º ğ˜”ğ˜“ ğ˜šğ˜ºğ˜´ğ˜µğ˜¦ğ˜®ğ˜´ ğ˜ğ˜ªğ˜µğ˜© ğ˜‹ğ˜¢ğ˜µğ˜¢ ğ˜ğ˜¢ğ˜­ğ˜ªğ˜¥ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜¢ğ˜¯ğ˜¥ ğ˜™ğ˜¦ğ˜¢ğ˜­-ğ˜›ğ˜ªğ˜®ğ˜¦ ğ˜”ğ˜°ğ˜¯ğ˜ªğ˜µğ˜°ğ˜³ğ˜ªğ˜¯ğ˜¨. Link in the comments â†“\nhashtag\n#\nmlops\nhashtag\n#\nmachinelearning\nhashtag\n#\ndata\n-----\nğŸ’¡ Follow me for daily lessons about ML engineering and MLOps."
  },
  {
    "instruction": "Post a LinkedIn update reflecting on the inherent challenges in programming, with a special emphasis on the complexities encountered in AI. Use the hashtags #machinelearning, #artificialintelligence, and #mlops to engage with relevant communities.",
    "post": "The saddest truth about programming.\nEven amplified if you work in AI.\nhashtag\n#\nmachinelearning\nhashtag\n#\nartificialintelliegence\nhashtag\n#\nmlops"
  },
  {
    "instruction": "Announce on LinkedIn the upcoming release of comprehensive lessons from The Full Stack 7-Steps MLOps Framework. Encourage engagement by using the hashtags #learning, #machinelearning, and #mlops.",
    "post": "Close to releasing all the lessons from The Full Stack 7-Steps MLOps Framework.\nhashtag\n#\nlearning\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops"
  },
  {
    "instruction": "Share on LinkedIn insights from Paul Iusztin's series on a 7-step MLOps framework, focusing on the latest installment about model predictions consumption and visualization. Enhance the post with an image to attract more views.",
    "post": "As\nPaul Iusztin\n's series continues to explore a 7-step MLOps framework, a new installment explains how to consume and visualize your model's predictions."
  },
  {
    "instruction": "Discuss the importance of building a 'second brain' especially in data and AI fields on LinkedIn. Highlight key takeaways from Tiago Forte's book on productivity and organizing information, using hashtags #productivity and #secondbrain.",
    "post": "I am always anxious that I forget what I read.\nThat is why I built my second brain.\nIf you are working in any data/AI-related field, you are constantly bombarded with information.\nMuch of it is noise,  but some will be of great value.\n.\nHere are the main ideas I extracted from the ğ˜‰ğ˜¶ğ˜ªğ˜­ğ˜¥ğ˜ªğ˜¯ğ˜¨ ğ˜¢ ğ˜šğ˜¦ğ˜¤ğ˜°ğ˜¯ğ˜¥ ğ˜‰ğ˜³ğ˜¢ğ˜ªğ˜¯ ğ˜£ğ˜º ğ˜›ğ˜ªğ˜¢ğ˜¨ğ˜° ğ˜ğ˜°ğ˜³ğ˜µğ˜¦ famous book ğŸ‘‡\n#ğŸ­. Your brain's job is to plan, create and enjoy life, not to remember things.\n#ğŸ®. Four steps to follow:\n1. Capture the relevant ideas\n2. Organize by actionability\n3. Distill your notes to prevent from hoarding\n4. Use & express your work\n#ğŸ¯. Follow the PARA system to organize your information:\nP - Projects: bounded responsibilities\nA - Areas: timeless responsibilities\nR - Resources: useful data\nA - Archive: your graveyard\n#ğŸ°. Main productivity tools:\n- calendar\n- TODOist\n- note-taking app\n- Notion: the central hub\nThe tools are not revolutionary.\nYou need the right mindset to apply them consistently in the right way.\n.\nTo conclude...\nYou must create a robust system to capture & use all the essential information from your environment.\nOtherwise, you will overload your brain, forgetting important information and wasting opportunities.\nDo you have a second brain?\nhashtag\n#\nproductivity\nhashtag\n#\nsecondbrain"
  },
  {
    "instruction": "On LinkedIn, stress the critical nature of validating data at every stage in the ML model lifecycle. Share a detailed post with an image illustrating the concept and use hashtags #data, #machinelearning, and #mlops.",
    "post": "A wise man said: ğ˜ƒğ—®ğ—¹ğ—¶ğ—±ğ—®ğ˜ğ—² ğ—²ğ˜ƒğ—²ğ—¿ğ˜†ğ˜ğ—µğ—¶ğ—»ğ—´!\n100% you heard that data validation is good...\nbut where should we validate the data? Everywhere!\nThat might be an overstatement, but let me explain.\nWhen the outputs of an ML model are poor, there are 1000+ reasons why that happened.\nBut even if you know that the issue is data related...\nNarrowing down to the actual function that messed up everything is extremely hard.\nThus, by adding data validation before & after:\n- the ingestion ETL;\n- the data engineering pipeline;\n- the feature engineering pipeline;\nyou might add some redundancy, but this will make scanning for errors extremely easy.\n.\nImagine that you would have a data validation check only after the FE pipeline. If that fails, you know it failed ğ˜£ğ˜¶ğ˜µ ğ˜¥ğ˜°ğ˜¯'ğ˜µ ğ˜¬ğ˜¯ğ˜°ğ˜¸ ğ˜¸ğ˜©ğ˜¦ğ˜³ğ˜¦ ğ˜ªğ˜µ ğ˜§ğ˜¢ğ˜ªğ˜­ğ˜¦ğ˜¥.\nIf the system is small, that is not an issue, but imagine you have 100+ transformations spread across multiple teams...\nğŸ¥² Finding the right error might take you hours or even days.\nğŸ’› By adding multiple data validation points in your system, you can quickly answer to: \"where the system failed\".\nThus, by adding data validation in multiple, you automatically slice the pipeline making it easy to diagnose.\n.\nNote that this is just an example. Your data infrastructure might look different.\nBut the fundamental idea remains the same. Add data validation in all the essential points of your data pipelines to quickly slice and dice the upcoming errors.\nIf you want a hands-on example about using GE to validate your data, check out my article ğ˜Œğ˜¯ğ˜´ğ˜¶ğ˜³ğ˜ªğ˜¯ğ˜¨ ğ˜›ğ˜³ğ˜¶ğ˜´ğ˜µğ˜¸ğ˜°ğ˜³ğ˜µğ˜©ğ˜º ğ˜”ğ˜“ ğ˜šğ˜ºğ˜´ğ˜µğ˜¦ğ˜®ğ˜´ ğ˜ğ˜ªğ˜µğ˜© ğ˜‹ğ˜¢ğ˜µğ˜¢ ğ˜ğ˜¢ğ˜­ğ˜ªğ˜¥ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜¢ğ˜¯ğ˜¥ ğ˜™ğ˜¦ğ˜¢ğ˜­-ğ˜›ğ˜ªğ˜®ğ˜¦ ğ˜”ğ˜°ğ˜¯ğ˜ªğ˜µğ˜°ğ˜³ğ˜ªğ˜¯ğ˜¨. Link in the comments ğŸ‘‡\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\n-----\nğŸ’¡ Follow me if you want to level up in designing and productionizing ML systems."
  },
  {
    "instruction": "Promote a weekly newsletter on real-world ML and MLOps by Pau Labarta Bajo on LinkedIn, highlighting its value for ML developers. Include the newsletter's link and use relevant hashtags to attract interested audiences.",
    "post": "Do you want to learn ML & MLOps from real-world experience?\nThen I suggest you join\nPau Labarta Bajo\nReal-World Machine Learning\nweekly newsletter, along with another 7.5 ML developer.\nPau Labarta Bajo\nis a great teacher that makes learning seamless âœŒ\nâ†’\nhttps://lnkd.in/dXx-GxN8\nhashtag\n#\nmachinelearning\nhashtag\n#\ndata\nhashtag\n#\nmlops"
  },
  {
    "instruction": "Share a concise guide to data validation in ML systems on LinkedIn, emphasizing the simplicity and effectiveness of using Great Expectations. Encourage followers to learn more through an article linked in the comments.",
    "post":  "ğ——ğ—®ğ˜ğ—® ğ˜ƒğ—®ğ—¹ğ—¶ğ—±ğ—®ğ˜ğ—¶ğ—¼ğ—» shouldn't be hard.\nHere is your data validation guide in under 2 minutes ğŸ‘‡\nData validation ensures the integrity and quality of your data ingested automatically into your ML system.\nThus, implementing your data validation layer is crucial in any successful ML system.\n.\nğŸ§˜ğŸ¼â€â™‚ï¸ ğ˜ğ˜³ğ˜¦ğ˜¢ğ˜µ ğ˜Œğ˜¹ğ˜±ğ˜¦ğ˜¤ğ˜µğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ğ˜´ makes everything straightforward.\nUsing GE, you must stack multiple ğ˜Œğ˜¹ğ˜±ğ˜¦ğ˜¤ğ˜µğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ğ˜Šğ˜°ğ˜¯ğ˜§ğ˜ªğ˜¨ğ˜¶ğ˜³ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ objects, where each object checks a single rule/feature.\nFor example:\n\"\"\"\nExpectationConfiguration(\nexpectation_type=\"expect_column_distinct_values_to_be_in_set\",\nkwargs={\"column\": \"area\", \"value_set\": (0, 1, 2)},\n)\n\"\"\"\n, checks if the \"area\" feature contains only values equal to 0, 1 or 2.\nThe most common checks you have to do are for the following:\n- the schema of the table;\n- the type of each column;\n- the values of each column: an interval for continuous variables or an expected set for discrete variables;\n- null values.\n.\nAfter you run your GE validation suit, you will get a success %.\nBased on the success % you can make various decisions, such as:\nğŸŸ¢  == 100% - ingest the data without an alert\nğŸŸ¡  >=90% - ingest the data with an alert\nğŸ”´   <90% - drop the data with an error\nP.S. Using GE +\nHopsworks\nas your Feature Store makes everything even simpler ğŸ”¥\n.\nSo remember...\nGE makes implementing your data validation layer straightforward.\nYou have to check every feature for a given set of rules.\nBased on the success % you have to take various actions.\nIf you want a hands-on example about using GE to validate your data, check out my article ğ˜Œğ˜¯ğ˜´ğ˜¶ğ˜³ğ˜ªğ˜¯ğ˜¨ ğ˜›ğ˜³ğ˜¶ğ˜´ğ˜µğ˜¸ğ˜°ğ˜³ğ˜µğ˜©ğ˜º ğ˜”ğ˜“ ğ˜šğ˜ºğ˜´ğ˜µğ˜¦ğ˜®ğ˜´ ğ˜ğ˜ªğ˜µğ˜© ğ˜‹ğ˜¢ğ˜µğ˜¢ ğ˜ğ˜¢ğ˜­ğ˜ªğ˜¥ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜¢ğ˜¯ğ˜¥ ğ˜™ğ˜¦ğ˜¢ğ˜­-ğ˜›ğ˜ªğ˜®ğ˜¦ ğ˜”ğ˜°ğ˜¯ğ˜ªğ˜µğ˜°ğ˜³ğ˜ªğ˜¯ğ˜¨. Link in the comments ğŸ‘‡\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\n-----\nğŸ’¡ Follow me if you want to level up in designing and productionizing ML systems."
  },
  {
    "instruction": "Educate your LinkedIn network on mastering Terraform for clean and modular infrastructure management in ML projects, highlighting the use of variables. Use relevant hashtags to reach a wider audience interested in #machinelearning, #artificialintelligence, and #mlops.",
    "post": "Master writing clean & modular Terraform files.\nUsing this one simple technique:\nVariables\nLet's take a look at how to:\n- define a variable\n- reference a variable\n- assign a value to a variable\n- use files to assign values to variables\n... in Terraform.\nNote that assigning values in Terraform is quite strange, as in your Terraform file, you define the structure and type of the variable. The value is assigned only on runtime.\nhashtag\n#\nmachinelearning\nhashtag\n#\nartificialintelliegence\nhashtag\n#\nmlops\n-----\nğŸ’¡ Follow me if you want to level up in designing and productionizing ML systems."
  },
  {
    "instruction": "Discuss the common starting point of serving ML models in batch mode on LinkedIn, covering the essential components and transitions to other architectures. Provide insights for ML engineers on optimizing model performance.",
    "post": "90% of the ML models start being served in batch mode.\nThus, as an ML engineer, learning to train and serve a model in batch mode successfully is your first step to success.\nYou need to know how to implement the following:\n- a feature engineering pipeline\n- a training pipeline\n- a batch prediction pipeline\n- a feature store\n- an ML Platform\n- a storage system to store your predictions\nMany ML systems start in batch mode and naturally move toward other architectures.\nThis happens because serving an ML model in batch mode is the fastest without spending too much time on constraints such as low latency and high throughput.\nRemember that while in production, if your model isn't running fast enough, it will probably be useless.\nIf you want to learn how to implement the steps above step-by-step practically,\nI want to let you know that...\nI finally released the first 3 lessons for  \"The Full Stack 7-Steps MLOps Framework\" FREE course that will teach you just that.\nThe lessons are accessible on Towards Data Science Medium's publication.\nCheck the comments for the links...\nAnd start learning about training and serving your ML model in batch mode.\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops"
  },
  {
    "instruction": "On LinkedIn, share insights on the advantages of serving ML models using a batch architecture, focusing on the initial deployment phase. Emphasize the process and its impact on system flexibility and user experience.",
    "post": "Why serving an ML model using a batch architecture is so powerful?\nWhen you first start deploying your ML model, you want an initial end-to-end flow as fast as possible.\nDoing so lets you quickly provide value, get feedback, and even collect data.\nBut here is the catch...\nSuccessfully serving an ML model is tricky as you need many iterations to optimize your model to work in real-time:\n- low latency\n- high throughput\nInitially, serving your model in batch mode is like a hack.\nBy storing the model's predictions in dedicated storage, you automatically move your model from offline mode to a real-time online model.\nThus, you no longer have to care for your model's latency and throughput. The consumer will directly load the predictions from the given storage.\nğ“ğ¡ğğ¬ğ ğšğ«ğ ğ­ğ¡ğ ğ¦ğšğ¢ğ§ ğ¬ğ­ğğ©ğ¬ ğ¨ğŸ ğš ğ›ğšğ­ğœğ¡ ğšğ«ğœğ¡ğ¢ğ­ğğœğ­ğ®ğ«ğ:\n- extracts raw data from a real data source\n- clean, validate, and aggregate the raw data within a feature pipeline\n- load the cleaned data into a feature store\n- experiment to find the best model + transformations using the data from the feature store\n- upload the best model from the training pipeline into the model registry\n- inside a batch prediction pipeline, use the best model from the model registry to compute the predictions\n- store the predictions in some storage\n- the consumer will download the predictions from the storage\n- repeat the whole process hourly, daily, weekly, etc. (it depends on your context)\nThe main downside of deploying your model in batch mode is that the predictions will have a level of lag.\nFor example, in a recommender system, if you make your predictions daily, it won't capture a user's behavior in real time, and it will update the predictions only at the end of the day.\nThat is why moving to other architectures, such as request-response or streaming, will be natural after your system matures in batch mode.\nSo remember, when you initially deploy your model, using a batch mode architecture will be your best shot for a good user experience.\nLet me know in the comments what your strategy is.\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\n-----\nğŸ’¡ My goal is to help machine learning engineers level up in designing and productionizing ML systems.\nğŸ‘‰ Follow me for weekly insights."
  },
  {
    "instruction": "Reveal three lesser-known methods for data transformation using a feature store in ML production systems on LinkedIn. Discuss the trade-offs and benefits of each method, inviting feedback from your network.",
    "post": "These are 3 ways you didn't know about how you can transform your data when using a feature store.\nA feature store helps you quickly solve the training serving skew issue by offering you a consistent way to transform your data into features between the training and inference pipelines.\nThe issue boils down to WHEN you do the transformation.\nWhen using a feature store, there are 3 main ways how you can transform your data:\nğŸ. ğğğŸğ¨ğ«ğ ğ¬ğ­ğ¨ğ«ğ¢ğ§ğ  ğ­ğ¡ğ ğğšğ­ğš ğ¢ğ§ ğ­ğ¡ğ ğŸğğšğ­ğ®ğ«ğ ğ¬ğ­ğ¨ğ«ğ\nIn the feature engineering pipeline, you do everything: clean, validate, aggregate, reduce, and transform your data.\nEven if this is the most intuitive way of doing things, it is the worse.\nğŸŸ¢ ultra-low latency\nğŸ”´ hard to do EDA on transformed data\nğŸ”´ store duplicated/redundant data\nğŸ. ğ’ğ­ğ¨ğ«ğ ğ­ğ¡ğ ğ­ğ«ğšğ§ğ¬ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§ ğ¢ğ§ ğ²ğ¨ğ®ğ« ğ©ğ¢ğ©ğğ¥ğ¢ğ§ğ ğ¨ğ« ğ¦ğ¨ğğğ¥ ğ©ğ«ğ-ğ©ğ«ğ¨ğœğğ¬ğ¬ğ¢ğ§ğ  ğ¥ğšğ²ğğ«ğ¬\nIn the feature engineering pipeline, you perform only the cleaning, validation, aggregations, and reductions steps.\nLater, by incorporating all your transformations into your pipeline object or pre-processing layers, you automatically save them along your model.\nThus, you can input your cleaned data into your pipeline, and it will know how to handle it.\nğŸŸ¢ store only cleaned data\nğŸŸ¢ easily explore your data\nğŸ”´ the transformations are done on the client\nğŸ‘. ğ˜ğ¨ğ® ğšğ­ğ­ğšğœğ¡ ğ­ğ¨ ğğ¯ğğ«ğ² ğœğ¥ğğšğ§ğğ ğğšğ­ğš ğ¬ğ¨ğ®ğ«ğœğ ğš ğ”ğƒğ… ğ­ğ«ğšğ§ğ¬ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§\nThis is similar to solution 2., but instead of attaching the transformation directly to your model, you attached them as a UDF to the feature store.\nfeature = cleaned data source + UDF\nSo when you request a feature, the feature store will automatically trigger the UDF on a server and return it.\nğŸŸ¢ store only cleaned data\nğŸŸ¢ easily explore your data\nğŸŸ¢ the transformations are done on the server\nğŸŸ¢ scalable (using Spark)\nğŸ”´ hard to implement\nAs a recap,\nThere are 3 ways when you can perform your transformations to solve the train serving skew when using a feature store.\nWhat method do you think is the best?\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\n-----\nI just started my ML engineering weekly newsletter.\nSubscribe to level up in building ML systems:\nhttps://lnkd.in/dsMR4ivA"
  },
  {
    "instruction": "Announce the launch of a weekly ML engineering newsletter on LinkedIn, emphasizing the commitment to providing value on ML system design and MLOps. Encourage sign-ups through a link and use relevant hashtags to attract interested readers.",
    "post": "After 3 months of overthinking...\nI finally did it.\nAs I value people's time, and I understand that everybody has their way of reading...\nI want to announce,\nThat I will start my free weekly ML engineering newsletter.\n.\nThe mission of my newsletter will be the same as my LinkedIn content:\n\"To help machine learning engineers level up in designing and productionizing ML systems.\"\nI will do my best to provide the best value for your time.\n.\nIf you never want to miss my weekly insights about ML engineering,\nSubscribe to my free newsletter here:\nhttps://lnkd.in/dsMR4ivA\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops"
  },
  {
    "instruction": "Summarize the top three ML monitoring resources discovered after reviewing over 100 articles on LinkedIn. Share links to these resources for followers seeking to deepen their understanding of ML system monitoring.",
    "post": "In the last month, I read 100+ ML monitoring articles.\nI trimmed them for you to 3 key resources:\n1. A series of excellent articles made by\nArize AI\nthat will make you understand what ML monitoring is all about.\nLink:\nhttps://lnkd.in/dDVWRujh\n2. The\nEvidently AI\nBlog, where you can find answers to all your questions regarding ML monitoring.\nLink:\nhttps://lnkd.in/du35hWp2\n3. The monitoring hands-on examples hosted by\nDataTalksClub\nwill teach you how to implement an ML monitoring system.\nLink:\nhttps://lnkd.in/d4ziHhxH\nAfter wasting a lot of time reading other resources...\nUsing these 3 resources is a solid start for learning about monitoring ML systems.\nHave you tried them?\nhashtag\n#\nmachinelearning\nhashtag\n#\ndata\nhashtag\n#\nmonitoring\n-----\nğŸ’¡ My goal is to help machine learning engineers level up in designing and productionizing ML systems."
  },
  {
    "instruction": "Celebrate reaching a follower milestone on LinkedIn while sharing personal insights and tips on brand building and engagement. Highlight the importance of consistency and adapting to feedback in content creation.",
    "post": "My dreams came true âœŒï¸\nWhile on vacation, I had the wonderful surprise of passing 5k followers on LinkedIn.\nAs a side note, Amsterdam is a beautiful place, and it 100% deserves to be on most of the go-to tourist destinations.\nFirst of all, I want to thank everybody who is reading my content. I am doing my best to provide you with value about ML engineering, building ML systems and MLOps.\nSecondly, I want to keep the tradition of sharing the key steps that got me here:\n1. Consistency when you have <10 likes\nWhen you are just starting, you probably havenâ€™t built trust around your online persona.\nThus most likely, you will be writing into the void.\nJust donâ€™t get discouraged. At some point, your content will gain traction.\n2. Just start and adapt along the way\nIt is hard to find your best niche, plan, etc., without any real feedback.\nStop overthinking and start posting.\nBut always listen and adapt to see what suits you and your audience better.\nAlways learn âœŒï¸\nSo...\nConsistency, regardless of your engagement and taking action when you think you donâ€™t know what you are doing are my two best pieces of advice for building your brand on LinkedIn.\nWhat do you think about my advice? Would you add something else?\nhashtag\n#\nmachinelearning\nhashtag\n#\nlinkedin\nhashtag\n#\nbrand\n---\nIf you want to learn more about ML engineering, ML systems, and MLOps...\nFollow me on LinkedIn and Medium ğŸ‘‡"
  },
  {
    "instruction": "On LinkedIn, emphasize the critical practice of versioning data in MLOps for managing changes in model embeddings and data processes. Discuss the types of changes and the importance of data versioning for clarity and system integrity.",
    "post": "This is one MLOps practice you 100% have to know.\nMany engineers ignore it,\nbut let me explain why it is so important.\nI showed you one post before about how to extract an embedding from your model.\nI showed you a few examples of extraction methods for various models.\nBut what happens if you want to change the extraction method or model to compare the performance?\nMost probably, it will soon become a mess.\nWe all encountered situations such as: \"final_model,\" \"best_final_model,\" \"best_final_final_model,\" etc. You get the idea... It is tough to keep track of our changes.\n.\n3 types of changes can occur when extracting embeddings:\n#ğŸ. ğ‚ğ¡ğšğ§ğ ğ ğ²ğ¨ğ®ğ« ğ¦ğ¨ğğğ¥ ğšğ«ğœğ¡ğ¢ğ­ğğœğ­ğ®ğ«ğ\nThis is considered a major change: O.x.x\nChanging your model architecture might change the semantics of the embeddings and their dimensionality. Also, as a by-product, it changes your extraction method, and you must retrain your model.\n#ğŸ. ğ‚ğ¡ğšğ§ğ ğ ğ²ğ¨ğ®ğ« ğğ±ğ­ğ«ğšğœğ­ğ¢ğ¨ğ§ ğ­ğ²ğ©ğ\nThis is considered a minor change: x.O.x\nAgain this might result in changes in your semantics or dimensionality, but you don't have to retrain your model.\n#ğŸ‘. ğ‘ğğ­ğ«ğšğ¢ğ§ ğ²ğ¨ğ®ğ« ğ¦ğ¨ğğğ¥\nThis is considered a patch version change: x.x.O\nThis won't change your embedding structure, but by retraining, they won't be compatible with your old set of embeddings as the vector space might change.\n.\nAs you see, your embeddings will change quite often, that is why you need to...\nVersion your data!\nData versioning is one key aspect of a clean ML system.\nEvery change will result in a new data version. Then, when you use a specific set of embeddings, you will know exactly how they were computed.\nYou can easily version your data directly in the feature store for structured data. You can quickly add data versioning for unstructured data using tools such as S3 + DVC/your custom software.\nTo conclude...\nYou should fire up a new version of your data whenever you change your data process.\nHow are you versioning your data?\nhashtag\n#\ndata\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\n-----\nğŸ’¡ My goal is to help machine learning engineers level up in designing and productionizing ML systems.\nğŸ‘‰ Follow me for weekly insights."
  },
  {
    "instruction": "Announce the completion of the \"Full Stack 7-Steps MLOps Framework\" series on LinkedIn, offering a comprehensive guide on designing, implementing, and deploying ML systems with MLOps best practices. Invite followers to access the course and share their projects.",
    "post": "After 3 months of hard work and no sleep...\nI can finally say that I know everything about MLOps.\nHehe, not really, but I have put in a lot of work and...\nI finally finished my hands-on \"Full Stack 7-Steps MLOps Framework\" series.\nThis a step-by-step course that will explain to you how to design, implement, and deploy an ML system using MLOps good practices.\nAt the end of the 7 lessons course, you will know how to:\n- design a batch-serving architecture\n- use Hopsworks as a feature store\n- design a feature engineering pipeline that reads data from an API\n- build a training pipeline with hyper-parameter tunning\n- use W&B as an ML Platform to track your experiments, models, and metadata\n- implement a batch prediction pipeline\n- use Poetry to build your own Python packages\n- deploy your own private PyPi server\n- orchestrate everything with Airflow\n- use the predictions to code a web app using FastAPI and Streamlit\n- use Docker to containerize your code\n- use Great Expectations to ensure data validation and integrity\n- monitor the performance of the predictions over time\n- deploy everything to GCP\n- build a CI/CD pipeline using GitHub Actions\nIf this sounds interesting to you.\nI want you to know that...\nThe course is free and published on Medium under the\nTowards Data Science\npublication so that anybody can level up their ML engineering journey.\nWant to start building your project?\nJust check out the GitHub repository and the first lesson of the series in the comments.\nhashtag\n#\nmachinelearning\nhashtag\n#\ndata\nhashtag\n#\nlearning\n-----\nI want to thank @Kurtis Pykes for helping me build this series and being an excellent copilot. It was a great collaboration."
  },
  {
    "instruction": "Highlight the importance of careful data validation and monitoring for maintaining the health of ML models in production on LinkedIn. Share an image summarizing the five main criteria to watch, using relevant hashtags to engage the community.",
    "post": "ML is more than training, evaluating and beating metrics.\nTo keep your model healthy while in production, you must carefully validate and monitor your data.\nThese are the 5 main criteria you have to be careful about.\nhashtag\n#\nml\nhashtag\n#\nmlops\nhashtag\n#\nmonitoring"
  }
]